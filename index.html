<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="/xgao.jpg" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Xiang Gao</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

</head>

<body>
  
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">Xiang Gao</font><br>
            xgao@ouc.edu.cn</p>

            <p>I am a assistant professor at <a href="http://coe.ouc.edu.cn/">College of Engineering</a>, <a href="http://www.ouc.edu.cn/">Ocean University of China</a> since 2019.08. Before that, I received my PhD from <a href="http://www.ia.cas.cn/">Institute of Automation</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I did my bachelors in <a href="http://www.ece.ntua.gr/">ECE</a> at <a href="http://www.ntua.gr/">NTUA</a> in Athens, Greece, where I worked with <a href="http://cvsp.cs.ntua.gr/maragos/">Petros Maragos</a>.</p>

            <p>In the past, I have spent time at Google Brain and Google Research, where I worked with <a href="http://www.cs.toronto.edu/~ndjaitly">Navdeep Jaitly</a> and <a href="https://research.google.com/pubs/AlexanderToshev.html">Alexander Toshev</a>.</p>
            
          </td>
          <td width="30%">
            <div class="instructorphoto">
              <img onmouseover="document.getElementById('xgao').src='/xgao-rear.jpg';"
              onmouseout="document.getElementById('xgao').src='/xgao-front.jpg';"src="xgao-front.jpg" id="xgao">
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>
  
  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul>
         <li><span> We released <a href="https://github.com/facebookresearch/pytorch3d">PyTorch3D</a>, a 3D deep learning library! Try it out! 
         <li><span> Thank you Re-Work! <a href="https://blog.re-work.co/top-women-in-ai-2019/">https://blog.re-work.co/top-women-in-ai-2019/</a></span></li>
         <li><span> I will be a Program Chair for CVPR 2021!</span></li>
         <li><span> At ICCV 2019, I gave a talk at the <a href="http://picdataset.com/challenge/index/">Person In Context</a> workshop, the <a href="https://sites.google.com/view/gmdl2019/home">Geometry Meets Deep Learning</a> workshop, as well as the </a>
         <a href="https://alexander-kirillov.github.io/tutorials/visual-recognition-iccv19/">Visual Recognition for Images, Video and 3D</a> tutorial.
         <li><span> At CVPR 2019, I gave at talk at the <a href="https://sites.google.com/view/sem-vis-nav">Deep Learning for Visual Navigation</a> workshop and the <a href="https://motchallenge.net/workshops/bmtt2019/program.html">Benchmarking Multi-Target Tracking: How crowded can it get?</a> workshop. Slides are shared at the workshops' webpages.
         <li><span> I am excited to be (a tiny) part of the <a href="https://aims-ammi.com/">African Master's of Machine Intelligence</a> at AIMS (<a href="teasers/ammi.jpg">pic</a>)</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>
  
  <div class="container">
    <h2> Selected Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://www.sciencedirect.com/sdfe/reader/pii/S092427161830131X/pdf"><heading>Ancient Chinese Architecture 3D Preservation by Merging Ground and Aerial Point Clouds</heading></a><br>
          <strong>Xiang Gao</strong>, Shuhan Shen, Yang Zhou, Hainan Cui, Lingjie Zhu, and Zhanyi Hu<br>
          <a href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing"><em>ISPRS Journal of Photogrammetry and Remote Sensing (P&RS)</em></a>, 2018. (IF: 6.942, h5-index: 69)
        </td>
        </td>
      </table>
    </div>
    <hr>

   <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://www.sciencedirect.com/sdfe/reader/pii/S0031320317304570/pdf"><heading>Accurate and Efficient Ground-to-Aerial Model Alignment</heading></a><br>
          <strong>Xiang Gao</strong>, Lihua Hu, Hainan Cui, Shuhan Shen, and Zhanyi Hu<br>
          <a href="https://www.sciencedirect.com/journal/pattern-recognition"><em>Pattern Recognition (PR)</em></a>, 2018. (IF: 5.898, CCF-B, h5-index: 79)
        </td>
        </td>
      </table>
    </div>
    <hr>
    
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8850072"><heading>Complete Scene Reconstruction by Merging Images and Laser Scans</heading></a><br>
          <strong>Xiang Gao</strong>, Shuhan Shen, Lingjie Zhu, Tianxin Shi, Zhiheng Wang, and Zhanyi Hu<br>
          <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76"><em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em></a>, 2019. (IF: 4.046, CCF-B, h5-index: 63)
        </td>
        </td>
      </table>
    </div>
    <hr>
  
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://www.sciencedirect.com/sdfe/reader/pii/S0167865518303544/pdf"><heading>Ground and Aerial Meta-data Integration for Localization and Reconstruction: A Review</heading></a><br>
          <strong>Xiang Gao</strong>, Shuhan Shen, Zhanyi Hu, and Zhiheng Wang<br>
          <a href="https://www.sciencedirect.com/journal/pattern-recognition-letters"><em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em></a>, 2019. (IF: 2.810, CCF-C, h5-index: 55)
        </td>
        </td>
      </table>
    </div>
    <hr>
  
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a><heading>Urban Scene Vectorized Modeling Based on Contour Deformation</heading></a><br>
          Lingjie Zhu, Shuhan Shen, <strong>Xiang Gao</strong>, and Zhanyi Hu<br>
          <a href="https://www.mdpi.com/journal/ijgi"><em>ISPRS International Journal of Geo-Information (IJGI)</em></a>, 2020. (IF: 1.840, h5-index: 31)
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://www.sciencedirect.com/sdfe/reader/pii/S2096579619300671/pdf"><heading>Multi-source Data-based 3D Digital Preservation of Large-scale Ancient Chinese Architecture: A Case Report</heading></a><br>
          <strong>Xiang Gao</strong>, Hainan Cui, Lingjie Zhu, Tianxin Shi, and Shuhan Shen<br>
          <a href="https://www.sciencedirect.com/journal/virtual-reality-and-intelligent-hardware"><em>Virtual Reality & Intelligent Hardware (VRIH)</em></a>, 2019.
        </td>
        </td>
      </table>
    </div>
    <hr>
  
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="teasers/armlets.png" alt="armlets" width="160" height="120" style="border-style: none">  
        <td width="75%" valign="top">
          <p><a href="https://www.dropbox.com/s/r6vb6ace88hhrh9/GkioxariCVPR2013.pdf?dl=0"><heading>Articulated Pose Estimation using Discriminative Armlet Classifiers</heading></a><br>
          <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/"> Pablo Arbelaez</a>, <a href="http://www.lubomir.org/"> Lubomir Bourdev</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2013 &nbsp 
        </td>
        </td>
      </table>
    </div>
  </div>
  <br>
  
</body>

</html>
